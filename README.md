# Artwork-Similarity-Search
A machine learning-powered art recommender and visual similarity search using open museum images and CLIP embeddings.

This project aims to understand the similarity between the artwork displayed in Instute of Art Chicago, Metropolitan Museum of Art, and Cleveland Art Museum. 

Given a query artwork, the system finds the most visually similar artworks from 1000+ open-access images using CLIP embeddings.

Apart from the limitations in the API (especially the MET), CLIP embeddings are semantic, so the results are not purely visualâ€”they can capture abstract features, artist styles, or text associations.

# API DOCUMENTATION :
https://api.artic.edu/docs/
https://openaccess-api.clevelandart.org/#appendix-d
https://metmuseum.github.io/


Embed each artwork with OpenAIâ€™s **CLIP (ViT-B/32)** to produce vector representations, then given a **query image** (by URL or upload), retrieve the most visually/semantically similar artworks via cosine similarity.


The provided `Artwork-Similarity-Search.ipynb` implements the core pipeline:
1. **Fetch** public-domain artworks and metadata from the three museum APIs.
2. **Download** their images.
3. **Embed** each image with CLIP and normalize the feature vectors.
4. **Serialize / cache** embeddings and associated metadata to avoid repeated computation.
5. **Query logic**: given a new image, compute its embedding and find nearest neighbors in the corpus.
6. **Visual evaluation**: display top-k similar artworks for a sample query to sanity-check retrieval quality.

## ðŸ“¦ Dependencies

Install prerequisites (ideally in a virtualenv):
```bash
python -m venv venv
source venv/bin/activate
pip install --upgrade pip setuptools wheel
pip install torch ftfy regex tqdm requests Pillow scikit-learn numpy
pip install git+https://github.com/openai/CLIP.git
